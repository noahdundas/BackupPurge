## Backup Purge
This project was to create a system of managing my company's client backups. When creating a backup, a client could choose if they wanted their backups to be stored in Amazon Web Services or Google Cloud Platform, and additionally, clients could set a backup to be created automatically each day. However, old backups were never removed, and as years passed the company's methods of labelling and organizing these backups changed. This eventually lead to a massive backlog of outdated backups in various formats spread between two different storage providers for each of the company's clients. Needless to say, this greatly increased complexity and maintenance costs. To resolve the issue, I developed a set of AWS and GCP API utility functions (_file-management-utils.js_, _amazon-s3-utils.js_, _google-cloud-storage-v2.js_) and a script (_purgeScript.js_) which would retrieve the backups from both providers, organize them by date, and delete each backup that is older than the maximum quantity of backups that the client desired to keep. This script was set to run daily so that even as clients continued to create manual and automatic backups, they could no longer generate a backlog.

For company security, all identifying information has been redacted. Additionally, the company's file management functions unrelated to this project have been removed for clarity and concision.

### Shell Scripts
I have also included two utility shell scripts (_awslogin.sh_, _awsS3scan.sh_) with this project. These scripts are not used directly by the backup purge script or its utility methods, but were useful in the day-to-day operations of the company when interacting with AWS, and so are valuable in demonstrating my proficiency using shell scripts to automate processes that would otherwise be tedious or complex.
